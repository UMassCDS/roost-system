{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae2c4202",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Under Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "print(\"torch.get_num_threads: \", torch.get_num_threads())\n",
    "from roosts.data.downloader import Downloader\n",
    "from roosts.data.renderer import Renderer\n",
    "from roosts.detection.detector import Detector\n",
    "from roosts.tracking.tracker import Tracker\n",
    "from roosts.utils.visualizer import Visualizer\n",
    "from roosts.utils.postprocess import Postprocess\n",
    "import roosts.utils.file_util as fileUtil\n",
    "import copy\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import logging\n",
    "import time\n",
    "import argparse\n",
    "\n",
    "here = os.path.dirname(os.path.realpath(__file__))\n",
    "CKPT_PATH = f\"{here}/../checkpoints/entire_c4_9anchor.pth\" # detector model\n",
    "OUTPUT_DIR = f\"{here}/tmp\" # directory to store downloaded radar scans, rendered arrays, and roost track visualization\n",
    "os.path.makedirs(OUTPUT_DIR)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# pick the station and the date to run the system for\n",
    "\n",
    "STATION = \"KTYX\"\n",
    "DATE = \"20160803\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "######################## Initialize models ############################\n",
    "downloader = Downloader(min_before_sunrise=30, min_after_sunrise=90, log_dir=log_root_dir)\n",
    "downloader.set_request(request, scan_dir)\n",
    "renderer = Renderer(npz_dir, ui_img_dir)\n",
    "detector = Detector(\n",
    "    args.ckpt_path,\n",
    "    anchor_sizes = [[16, 32, 48, 64, 80, 96, 112, 128, 144]], # [[32], [64], [128], [256], [512]] for FPN\n",
    "    use_gpu = torch.cuda.is_available()\n",
    ")\n",
    "tracker = Tracker()\n",
    "visualizer = Visualizer()\n",
    "postprocess = Postprocess(\n",
    "    imsize = 600,\n",
    "    geosize = 300000,\n",
    "    clean_windfarm = True,\n",
    "    clean_rain = True\n",
    ")\n",
    "n_existing_tracks = 0\n",
    "\n",
    "\n",
    "######################## process radar data ############################\n",
    "print(\"Total number of days: %d\" % len(downloader))\n",
    "print(f\"---------------------- Day 1 -----------------------\\n\")\n",
    "\n",
    "######################## (1) Download data ############################\n",
    "for day_idx, downloader_outputs in enumerate(downloader):\n",
    "\n",
    "    if downloader_outputs is StopIteration:\n",
    "        break\n",
    "    else:\n",
    "        scan_paths, start_time, key_prefix, logger = downloader_outputs\n",
    "        year, month, _, _ = key_prefix.split(\"/\")\n",
    "\n",
    "    ######################## (2) Render data ############################\n",
    "    \"\"\"\n",
    "        npz_files: for detection module to load/preprocess data\n",
    "        img_files: for visualization\n",
    "        scan_names: for tracking module to know the full image set\n",
    "    \"\"\"\n",
    "\n",
    "    npz_files, img_files, scan_names = renderer.render(scan_paths, key_prefix, logger)\n",
    "    fileUtil.delete_files(scan_paths)\n",
    "\n",
    "    with open(os.path.join(\n",
    "            scan_and_track_dir, f'scans_{args.station}_{args.start}_{args.end}.txt'\n",
    "    ), \"a+\") as f:\n",
    "        f.writelines([scan_name + \"\\n\" for scan_name in scan_names])\n",
    "\n",
    "    if len(npz_files) == 0:\n",
    "        print()\n",
    "        if day_idx + 2 <= len(downloader):\n",
    "            print(f\"---------------------- Day {day_idx + 2} -----------------------\\n\")\n",
    "        continue\n",
    "\n",
    "    ######################## (3) Run detection models on the data ############################\n",
    "    detections = detector.run(npz_files)\n",
    "    logger.info(f'[Detection Done] {len(detections)} detections')\n",
    "\n",
    "    ######################## (4) Run tracking on the detections  ############################\n",
    "    \"\"\"\n",
    "        in some cases, the detector does not find any roosts,\n",
    "        therefore, we need \"scan_names\" (a name list of all scans) to let the tracker find some using tracking info\n",
    "        NMS over tracks is applied to remove duplicated tracks, not sure if it's useful with new detection model\n",
    "    \"\"\"\n",
    "    tracked_detections, tracks = tracker.tracking(scan_names, copy.deepcopy(detections))\n",
    "    logger.info(f'[Tracking Done] {len(tracks)} tracks with {len(tracked_detections)} tracked detections')\n",
    "\n",
    "    # ######################## (5) Postprocessing  ############################\n",
    "    # \"\"\"\n",
    "    #     (1) convert image coordinates to geometric coordinates;\n",
    "    #     (2) clean up the false positives due to windfarm and rain using auxiliary information\n",
    "    # \"\"\"\n",
    "    cleaned_detections, tracks = postprocess.annotate_detections(copy.deepcopy(tracked_detections),\n",
    "                                                          copy.deepcopy(tracks),\n",
    "                                                          npz_files)\n",
    "    logger.info(f'[Postprocessing Done] {len(cleaned_detections)} cleaned detections')\n",
    "\n",
    "    ######################## (6) Visualize the detection and tracking results  ############################\n",
    "    \n",
    "    \"\"\" visualize detections under multiple thresholds of detection score\"\"\"\n",
    "    gif_path1 = visualizer.draw_dets_multi_thresh(\n",
    "        img_files, copy.deepcopy(detections), os.path.join(vis_det_dir, args.station, year, month)\n",
    "    )\n",
    "\n",
    "    \"\"\" visualize results after NMS and merging on tracks\"\"\"\n",
    "    gif_path2 = visualizer.draw_tracks_multi_thresh(\n",
    "        img_files, copy.deepcopy(tracked_detections), copy.deepcopy(tracks),\n",
    "        os.path.join(vis_NMS_MERGE_track_dir, args.station, year, month)\n",
    "    )\n",
    "    \n",
    "    # generate a website file\n",
    "    station_day = scan_names[0][:12]\n",
    "    n_existing_tracks = visualizer.generate_web_files(\n",
    "        cleaned_detections, tracks, os.path.join(\n",
    "            scan_and_track_dir, f'tracks_{args.station}_{args.start}_{args.end}.txt'\n",
    "        ), n_existing_tracks=n_existing_tracks\n",
    "    )\n",
    "\n",
    "    end_time = time.time()\n",
    "    logger.info(f'[Finished] running the system on {station_day}; '\n",
    "                f'total time elapse: {end_time - start_time}')\n",
    "\n",
    "    print(\"Total time elapse: {}\".format(end_time - start_time))\n",
    "    print()\n",
    "    if day_idx + 2 <= len(downloader):\n",
    "        print(f\"-------------------- Day {day_idx + 2} --------------------\\n\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da9d835",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################## Initialize models ############################\n",
    "downloader = Downloader(min_before_sunrise=30, min_after_sunrise=90, log_dir=log_root_dir)\n",
    "downloader.set_request(request, scan_dir)\n",
    "renderer = Renderer(npz_dir, ui_img_dir)\n",
    "detector = Detector(\n",
    "    args.ckpt_path,\n",
    "    anchor_sizes = [[16, 32, 48, 64, 80, 96, 112, 128, 144]], # [[32], [64], [128], [256], [512]] for FPN\n",
    "    use_gpu = torch.cuda.is_available()\n",
    ")\n",
    "tracker = Tracker()\n",
    "visualizer = Visualizer()\n",
    "postprocess = Postprocess(\n",
    "    imsize = 600,\n",
    "    geosize = 300000,\n",
    "    clean_windfarm = True,\n",
    "    clean_rain = True\n",
    ")\n",
    "n_existing_tracks = 0\n",
    "\n",
    "\n",
    "######################## process radar data ############################\n",
    "print(\"Total number of days: %d\" % len(downloader))\n",
    "print(f\"---------------------- Day 1 -----------------------\\n\")\n",
    "\n",
    "######################## (1) Download data ############################\n",
    "for day_idx, downloader_outputs in enumerate(downloader):\n",
    "\n",
    "    if downloader_outputs is StopIteration:\n",
    "        break\n",
    "    else:\n",
    "        scan_paths, start_time, key_prefix, logger = downloader_outputs\n",
    "        year, month, _, _ = key_prefix.split(\"/\")\n",
    "\n",
    "    ######################## (2) Render data ############################\n",
    "    \"\"\"\n",
    "        npz_files: for detection module to load/preprocess data\n",
    "        img_files: for visualization\n",
    "        scan_names: for tracking module to know the full image set\n",
    "    \"\"\"\n",
    "\n",
    "    npz_files, img_files, scan_names = renderer.render(scan_paths, key_prefix, logger)\n",
    "    fileUtil.delete_files(scan_paths)\n",
    "\n",
    "    with open(os.path.join(\n",
    "            scan_and_track_dir, f'scans_{args.station}_{args.start}_{args.end}.txt'\n",
    "    ), \"a+\") as f:\n",
    "        f.writelines([scan_name + \"\\n\" for scan_name in scan_names])\n",
    "\n",
    "    if len(npz_files) == 0:\n",
    "        print()\n",
    "        if day_idx + 2 <= len(downloader):\n",
    "            print(f\"---------------------- Day {day_idx + 2} -----------------------\\n\")\n",
    "        continue\n",
    "\n",
    "    ######################## (3) Run detection models on the data ############################\n",
    "    detections = detector.run(npz_files)\n",
    "    logger.info(f'[Detection Done] {len(detections)} detections')\n",
    "\n",
    "    ######################## (4) Run tracking on the detections  ############################\n",
    "    \"\"\"\n",
    "        in some cases, the detector does not find any roosts,\n",
    "        therefore, we need \"scan_names\" (a name list of all scans) to let the tracker find some using tracking info\n",
    "        NMS over tracks is applied to remove duplicated tracks, not sure if it's useful with new detection model\n",
    "    \"\"\"\n",
    "    tracked_detections, tracks = tracker.tracking(scan_names, copy.deepcopy(detections))\n",
    "    logger.info(f'[Tracking Done] {len(tracks)} tracks with {len(tracked_detections)} tracked detections')\n",
    "\n",
    "    # ######################## (5) Postprocessing  ############################\n",
    "    # \"\"\"\n",
    "    #     (1) convert image coordinates to geometric coordinates;\n",
    "    #     (2) clean up the false positives due to windfarm and rain using auxiliary information\n",
    "    # \"\"\"\n",
    "    cleaned_detections, tracks = postprocess.annotate_detections(copy.deepcopy(tracked_detections),\n",
    "                                                          copy.deepcopy(tracks),\n",
    "                                                          npz_files)\n",
    "    logger.info(f'[Postprocessing Done] {len(cleaned_detections)} cleaned detections')\n",
    "\n",
    "    ######################## (6) Visualize the detection and tracking results  ############################\n",
    "    \n",
    "    \"\"\" visualize detections under multiple thresholds of detection score\"\"\"\n",
    "    gif_path1 = visualizer.draw_dets_multi_thresh(\n",
    "        img_files, copy.deepcopy(detections), os.path.join(vis_det_dir, args.station, year, month)\n",
    "    )\n",
    "\n",
    "    \"\"\" visualize results after NMS and merging on tracks\"\"\"\n",
    "    gif_path2 = visualizer.draw_tracks_multi_thresh(\n",
    "        img_files, copy.deepcopy(tracked_detections), copy.deepcopy(tracks),\n",
    "        os.path.join(vis_NMS_MERGE_track_dir, args.station, year, month)\n",
    "    )\n",
    "    \n",
    "    # generate a website file\n",
    "    station_day = scan_names[0][:12]\n",
    "    n_existing_tracks = visualizer.generate_web_files(\n",
    "        cleaned_detections, tracks, os.path.join(\n",
    "            scan_and_track_dir, f'tracks_{args.station}_{args.start}_{args.end}.txt'\n",
    "        ), n_existing_tracks=n_existing_tracks\n",
    "    )\n",
    "\n",
    "    end_time = time.time()\n",
    "    logger.info(f'[Finished] running the system on {station_day}; '\n",
    "                f'total time elapse: {end_time - start_time}')\n",
    "\n",
    "    print(\"Total time elapse: {}\".format(end_time - start_time))\n",
    "    print()\n",
    "    if day_idx + 2 <= len(downloader):\n",
    "        print(f\"-------------------- Day {day_idx + 2} --------------------\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c50917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick the station and the date to run the system for\n",
    "\n",
    "STATION = \"KTYX\"\n",
    "DATE = \"20160803\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d74619",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b618281",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################## Initialize models ############################\n",
    "downloader = Downloader(min_before_sunrise=30, min_after_sunrise=90, log_dir=log_root_dir)\n",
    "downloader.set_request(request, scan_dir)\n",
    "renderer = Renderer(npz_dir, ui_img_dir)\n",
    "detector = Detector(\n",
    "    args.ckpt_path,\n",
    "    anchor_sizes = [[16, 32, 48, 64, 80, 96, 112, 128, 144]], # [[32], [64], [128], [256], [512]] for FPN\n",
    "    use_gpu = torch.cuda.is_available()\n",
    ")\n",
    "tracker = Tracker()\n",
    "visualizer = Visualizer()\n",
    "postprocess = Postprocess(\n",
    "    imsize = 600,\n",
    "    geosize = 300000,\n",
    "    clean_windfarm = True,\n",
    "    clean_rain = True\n",
    ")\n",
    "n_existing_tracks = 0\n",
    "\n",
    "\n",
    "######################## process radar data ############################\n",
    "print(\"Total number of days: %d\" % len(downloader))\n",
    "print(f\"---------------------- Day 1 -----------------------\\n\")\n",
    "\n",
    "######################## (1) Download data ############################\n",
    "for day_idx, downloader_outputs in enumerate(downloader):\n",
    "\n",
    "    if downloader_outputs is StopIteration:\n",
    "        break\n",
    "    else:\n",
    "        scan_paths, start_time, key_prefix, logger = downloader_outputs\n",
    "        year, month, _, _ = key_prefix.split(\"/\")\n",
    "\n",
    "    ######################## (2) Render data ############################\n",
    "    \"\"\"\n",
    "        npz_files: for detection module to load/preprocess data\n",
    "        img_files: for visualization\n",
    "        scan_names: for tracking module to know the full image set\n",
    "    \"\"\"\n",
    "\n",
    "    npz_files, img_files, scan_names = renderer.render(scan_paths, key_prefix, logger)\n",
    "    fileUtil.delete_files(scan_paths)\n",
    "\n",
    "    with open(os.path.join(\n",
    "            scan_and_track_dir, f'scans_{args.station}_{args.start}_{args.end}.txt'\n",
    "    ), \"a+\") as f:\n",
    "        f.writelines([scan_name + \"\\n\" for scan_name in scan_names])\n",
    "\n",
    "    if len(npz_files) == 0:\n",
    "        print()\n",
    "        if day_idx + 2 <= len(downloader):\n",
    "            print(f\"---------------------- Day {day_idx + 2} -----------------------\\n\")\n",
    "        continue\n",
    "\n",
    "    ######################## (3) Run detection models on the data ############################\n",
    "    detections = detector.run(npz_files)\n",
    "    logger.info(f'[Detection Done] {len(detections)} detections')\n",
    "\n",
    "    ######################## (4) Run tracking on the detections  ############################\n",
    "    \"\"\"\n",
    "        in some cases, the detector does not find any roosts,\n",
    "        therefore, we need \"scan_names\" (a name list of all scans) to let the tracker find some using tracking info\n",
    "        NMS over tracks is applied to remove duplicated tracks, not sure if it's useful with new detection model\n",
    "    \"\"\"\n",
    "    tracked_detections, tracks = tracker.tracking(scan_names, copy.deepcopy(detections))\n",
    "    logger.info(f'[Tracking Done] {len(tracks)} tracks with {len(tracked_detections)} tracked detections')\n",
    "\n",
    "    # ######################## (5) Postprocessing  ############################\n",
    "    # \"\"\"\n",
    "    #     (1) convert image coordinates to geometric coordinates;\n",
    "    #     (2) clean up the false positives due to windfarm and rain using auxiliary information\n",
    "    # \"\"\"\n",
    "    cleaned_detections, tracks = postprocess.annotate_detections(copy.deepcopy(tracked_detections),\n",
    "                                                          copy.deepcopy(tracks),\n",
    "                                                          npz_files)\n",
    "    logger.info(f'[Postprocessing Done] {len(cleaned_detections)} cleaned detections')\n",
    "\n",
    "    ######################## (6) Visualize the detection and tracking results  ############################\n",
    "    \n",
    "    \"\"\" visualize detections under multiple thresholds of detection score\"\"\"\n",
    "    gif_path1 = visualizer.draw_dets_multi_thresh(\n",
    "        img_files, copy.deepcopy(detections), os.path.join(vis_det_dir, args.station, year, month)\n",
    "    )\n",
    "\n",
    "    \"\"\" visualize results after NMS and merging on tracks\"\"\"\n",
    "    gif_path2 = visualizer.draw_tracks_multi_thresh(\n",
    "        img_files, copy.deepcopy(tracked_detections), copy.deepcopy(tracks),\n",
    "        os.path.join(vis_NMS_MERGE_track_dir, args.station, year, month)\n",
    "    )\n",
    "    \n",
    "    # generate a website file\n",
    "    station_day = scan_names[0][:12]\n",
    "    n_existing_tracks = visualizer.generate_web_files(\n",
    "        cleaned_detections, tracks, os.path.join(\n",
    "            scan_and_track_dir, f'tracks_{args.station}_{args.start}_{args.end}.txt'\n",
    "        ), n_existing_tracks=n_existing_tracks\n",
    "    )\n",
    "\n",
    "    end_time = time.time()\n",
    "    logger.info(f'[Finished] running the system on {station_day}; '\n",
    "                f'total time elapse: {end_time - start_time}')\n",
    "\n",
    "    print(\"Total time elapse: {}\".format(end_time - start_time))\n",
    "    print()\n",
    "    if day_idx + 2 <= len(downloader):\n",
    "        print(f\"-------------------- Day {day_idx + 2} --------------------\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "roost2021",
   "language": "python",
   "name": "roost2021"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}